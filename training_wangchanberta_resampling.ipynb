{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install accelerate -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.2.1\n",
      "2.2.6\n"
     ]
    }
   ],
   "source": [
    "import tqdm as notebook_tqdm\n",
    "import torch\n",
    "print(torch.__version__)\n",
    "from datasets import load_dataset, load_metric, Dataset, DatasetDict\n",
    "from transformers import TrainingArguments, Trainer, EarlyStoppingCallback, AutoTokenizer, AutoModel, AutoModelForSequenceClassification, pipeline\n",
    "import evaluate\n",
    "import pandas as pd\n",
    "pd.options.mode.chained_assignment = None  # default='warn'\n",
    "import numpy as np\n",
    "# import matplotlib.pyplot as plt\n",
    "# import matplotlib.cm as cm\n",
    "import re\n",
    "import emoji\n",
    "import itertools\n",
    "import pythainlp\n",
    "print(pythainlp.__version__)\n",
    "from pythainlp.tokenize import word_tokenize\n",
    "from pythainlp.corpus.common import thai_words, thai_stopwords\n",
    "stopwords = list(thai_stopwords())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, f1_score\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(file_name:str):\n",
    "    file_type = file_name.split(\"/\")[-1].split(\".\")[-1]\n",
    "    if file_type in ['xlsx', 'xls']:\n",
    "        return pd.read_excel(file_name)\n",
    "    elif file_type in ['csv']:\n",
    "        return pd.read_csv(file_name)\n",
    "    else:\n",
    "        raise ValueError(f\"The input data must be excel or csv file\")\n",
    "        # print(f\"The input data must be excel or csv file !!!\")\n",
    "        # sys.exit(1)\n",
    "\n",
    "def clean_text(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    text = re.sub(r'\\d+', '', text)\n",
    "    emoji_pattern = re.compile(\"[\"\n",
    "        u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "        u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "        u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "        u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "                           \"]+\", flags=re.UNICODE)\n",
    "    text = emoji_pattern.sub(r'', text) # no emoji\n",
    "    text = emoji.replace_emoji(text, \"\")\n",
    "    my_punctuation = '|!\"$-#@%^_*+,/&\\'()<=>?[\\\\]'\n",
    "    text = re.sub('['+ re.escape(my_punctuation) +']+', '', text)\n",
    "    text = re.sub(r'\\.{2,}', '', text)\n",
    "    text = re.sub(r'\\\\', '', text)\n",
    "    return text\n",
    "\n",
    "def new_word_tokenize(text):\n",
    "    lst_words = word_tokenize(text, keep_whitespace=False)\n",
    "    lst_words = [i for i in lst_words if i not in stopwords]\n",
    "    return lst_words\n",
    "\n",
    "def data_preprocessing(df, text_col, label_col):\n",
    "    # df = read_data('./data/new_data_group.xlsx')\n",
    "    data = df[[text_col, label_col]] # select text and class column\n",
    "    data['txt_type'] = data[text_col].apply(lambda x : isinstance(x, str)) # check str type\n",
    "    data = data[data['txt_type'] == True]\n",
    "    data = data.drop('txt_type', axis=1)\n",
    "    data['cln_text'] = data[text_col].apply(clean_text)\n",
    "    data['len_text'] = data['cln_text'].apply(len)\n",
    "    data = data[data['len_text'] > 0]\n",
    "    data = data.drop('len_text', axis=1)\n",
    "    data['cln_words'] = data['cln_text'].apply(str).apply(new_word_tokenize) # clean and tokenize\n",
    "    data['len_cln_words'] = data['cln_words'].apply(len)\n",
    "    data = data[data['len_cln_words'] > 0]\n",
    "    data = data.drop('len_cln_words', axis=1)\n",
    "    data['sent'] = data['cln_words'].apply(lambda x : \" \".join(x)) # join words\n",
    "    data['sent_cln'] = data['sent'].apply(lambda x : \"\".join(new_word_tokenize(x)))\n",
    "    # data = data[['sent', label_col]]\n",
    "    data = data[['sent_cln', label_col]]\n",
    "    data = data.rename({\"sent_cln\": \"sent\"}, axis=1)\n",
    "    print(\"Data size :\", data.shape)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>message</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>เช็คเบี้ยค่ะ</td>\n",
       "      <td>ใบเสนอราคา</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>เชคเบี้ยค่ะ</td>\n",
       "      <td>ใบเสนอราคา</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>เช็คเบี้ยคะ</td>\n",
       "      <td>ใบเสนอราคา</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>เช็คเบี้ย ป.1 ค่ะ</td>\n",
       "      <td>ใบเสนอราคา</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>เช็คเบี้ยต่ออายุค่ะ</td>\n",
       "      <td>ใบเสนอราคา</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               message       label\n",
       "0         เช็คเบี้ยค่ะ  ใบเสนอราคา\n",
       "1          เชคเบี้ยค่ะ  ใบเสนอราคา\n",
       "2          เช็คเบี้ยคะ  ใบเสนอราคา\n",
       "3    เช็คเบี้ย ป.1 ค่ะ  ใบเสนอราคา\n",
       "4  เช็คเบี้ยต่ออายุค่ะ  ใบเสนอราคา"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_excel('data/Re_label_row_data_5182.xlsx')\n",
    "df = df[['message','label']]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 'การชำระเงิน', 1: 'การอบรม', 2: 'ข้อความที่ไม่สามารถจัดหมวดหมู่ได้', 3: 'ข้อมูลประกัน', 4: 'คอมมิชชั่น', 5: 'งานกรมธรรม์', 6: 'งานประกันและการเคลม', 7: 'สมาชิกและนายหน้า', 8: 'อื่นๆ', 9: 'ใบเสนอราคา'}\n",
      "{'การชำระเงิน': 0, 'การอบรม': 1, 'ข้อความที่ไม่สามารถจัดหมวดหมู่ได้': 2, 'ข้อมูลประกัน': 3, 'คอมมิชชั่น': 4, 'งานกรมธรรม์': 5, 'งานประกันและการเคลม': 6, 'สมาชิกและนายหน้า': 7, 'อื่นๆ': 8, 'ใบเสนอราคา': 9}\n"
     ]
    }
   ],
   "source": [
    "# label encoding\n",
    "enc = LabelEncoder()\n",
    "enc.fit(df.label)\n",
    "idx2label = {k: v for k, v in enumerate(enc.classes_)}\n",
    "label2idx = {v: k for k, v in idx2label.items()}\n",
    "print(idx2label)\n",
    "print(label2idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>message</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>เช็คเบี้ยค่ะ</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>เชคเบี้ยค่ะ</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        message  label\n",
       "0  เช็คเบี้ยค่ะ      9\n",
       "1   เชคเบี้ยค่ะ      9"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['label'] = enc.transform(df['label'])\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data size : (4979, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sent</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>เช็คเบี้ย</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>เชคเบี้ย</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>เช็คเบี้ย</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>เช็คเบี้ยป.</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>เช็คเบี้ยต่ออายุ</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               sent  label\n",
       "0         เช็คเบี้ย      9\n",
       "1          เชคเบี้ย      9\n",
       "2         เช็คเบี้ย      9\n",
       "3       เช็คเบี้ยป.      9\n",
       "4  เช็คเบี้ยต่ออายุ      9"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# text preprocessing\n",
    "pp_df = data_preprocessing(df, 'message', 'label')\n",
    "pp_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "9    1226\n",
       "2    1075\n",
       "3     670\n",
       "0     525\n",
       "5     525\n",
       "4     301\n",
       "7     276\n",
       "6     252\n",
       "8      83\n",
       "1      46\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pp_df.label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "0    800\n",
       "1    800\n",
       "2    800\n",
       "3    800\n",
       "4    800\n",
       "5    800\n",
       "6    800\n",
       "7    800\n",
       "8    800\n",
       "9    800\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pp_df = pd.concat([pp_df[pp_df['label']==0].sample(n=800, replace=True),\n",
    "                   pp_df[pp_df['label']==1].sample(n=800, replace=True),\n",
    "                   pp_df[pp_df['label']==2].sample(n=800, replace=True),\n",
    "                   pp_df[pp_df['label']==3].sample(n=800, replace=True),\n",
    "                   pp_df[pp_df['label']==4].sample(n=800, replace=True),\n",
    "                   pp_df[pp_df['label']==5].sample(n=800, replace=True),\n",
    "                   pp_df[pp_df['label']==6].sample(n=800, replace=True),\n",
    "                   pp_df[pp_df['label']==7].sample(n=800, replace=True),\n",
    "                   pp_df[pp_df['label']==8].sample(n=800, replace=True),\n",
    "                   pp_df[pp_df['label']==9].sample(n=800, replace=True)], axis=0)\n",
    "\n",
    "pp_df.label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6400, 2) (1600, 2)\n"
     ]
    }
   ],
   "source": [
    "# split to train valid test set\n",
    "train_data, test_data = train_test_split(pp_df, test_size=0.2, random_state=99, stratify=pp_df['label'])\n",
    "# test_data, valid_data = train_test_split(test_data, test_size=0.5, random_state=31, stratify=test_data['label'])\n",
    "print(train_data.shape, test_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sent</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4821</th>\n",
       "      <td>รบกวนเช็คเบี้ยรถตู้รับจ้างทั่วไปรหัส</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2775</th>\n",
       "      <td>บัตร</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4844</th>\n",
       "      <td>บัตรนายหน้า</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2408</th>\n",
       "      <td>ตกลง</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1811</th>\n",
       "      <td>ติดไฟ</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4232</th>\n",
       "      <td>ผมแจ้งห้องผ่อนค่าเบี้ยเงินสดmessageนอกเวลาทำก</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3121</th>\n",
       "      <td>ยอดหักค่าคอมนะคะ</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2306</th>\n",
       "      <td>ตอนนี้ใบเตือนตัวแทนเหรอ</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3067</th>\n",
       "      <td>มาสด้ารบกวนนวกิจนะคะ</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>982</th>\n",
       "      <td>โทรลูกค้า</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               sent  label\n",
       "4821           รบกวนเช็คเบี้ยรถตู้รับจ้างทั่วไปรหัส      9\n",
       "2775                                           บัตร      2\n",
       "4844                                    บัตรนายหน้า      1\n",
       "2408                                           ตกลง      2\n",
       "1811                                          ติดไฟ      6\n",
       "4232  ผมแจ้งห้องผ่อนค่าเบี้ยเงินสดmessageนอกเวลาทำก      0\n",
       "3121                               ยอดหักค่าคอมนะคะ      4\n",
       "2306                        ตอนนี้ใบเตือนตัวแทนเหรอ      3\n",
       "3067                           มาสด้ารบกวนนวกิจนะคะ      7\n",
       "982                                       โทรลูกค้า      5"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert to huggingface dataset\n",
    "hg_train_data = Dataset.from_pandas(train_data)\n",
    "# hg_valid_data = Dataset.from_pandas(valid_data)\n",
    "hg_test_data = Dataset.from_pandas(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Pre-Trained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of CamembertForSequenceClassification were not initialized from the model checkpoint at airesearch/wangchanberta-base-att-spm-uncased and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"poom-sci/WangchanBERTa-finetuned-sentiment\", model_max_length=128) # set max length\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"airesearch/wangchanberta-base-att-spm-uncased\", num_labels=10) # set num class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # set label name\n",
    "model.config.id2label = idx2label\n",
    "model.config.label2id = label2idx\n",
    "# model.config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funtion to tokenize data\n",
    "def tokenize_dataset(data):\n",
    "    return tokenizer(data[\"sent\"],\n",
    "            max_length=128, # set max length\n",
    "            truncation=True,\n",
    "            padding=\"max_length\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a9f7c3cbe04444f9f7504c10ff9eab0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/6400 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "89c30b85a87d400883383f279657f3e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1600 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Tokenize the dataset\n",
    "dataset_train = hg_train_data.map(tokenize_dataset)\n",
    "dataset_test = hg_test_data.map(tokenize_dataset)\n",
    "# dataset_valid = hg_valid_data.map(tokenize_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Embedding(25004, 768)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# set embedding (if change)\n",
    "model.resize_token_embeddings(len(tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up training arguments\n",
    "NUM_STEP = 500 # 1000\n",
    "BATCH_SIZE = 8\n",
    "EPOCH = 30 # 20\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./checkpoint\",\n",
    "    save_total_limit=5,\n",
    "    overwrite_output_dir=True, \n",
    "    logging_dir='./logs',\n",
    "    logging_strategy='epoch',\n",
    "    logging_steps=NUM_STEP,\n",
    "    num_train_epochs=EPOCH,\n",
    "    fp16=True,\n",
    "    per_device_train_batch_size=BATCH_SIZE,\n",
    "    per_device_eval_batch_size=BATCH_SIZE,\n",
    "    learning_rate=1e-5, # 5e-5\n",
    "    # weight_decay=0.01, # use if larg model size\n",
    "    save_strategy= 'epoch',\n",
    "    save_steps=NUM_STEP,\n",
    "    evaluation_strategy='epoch',\n",
    "    eval_steps=NUM_STEP,\n",
    "    load_best_model_at_end=True\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define compute metrics\n",
    "def compute_metrics(eval_pred):\n",
    "    metric = load_metric(\"accuracy\")\n",
    "    logits, labels = eval_pred\n",
    "    predictions = logits.argmax(axis=-1)\n",
    "    return metric.compute(predictions=predictions, references=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=dataset_train,\n",
    "    eval_dataset=dataset_test,\n",
    "    compute_metrics=compute_metrics,\n",
    "    callbacks=[EarlyStoppingCallback(early_stopping_patience=10)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='20000' max='24000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [20000/24000 33:59 < 06:47, 9.81 it/s, Epoch 25/30]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.262800</td>\n",
       "      <td>2.215394</td>\n",
       "      <td>0.211250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.809100</td>\n",
       "      <td>1.389453</td>\n",
       "      <td>0.551875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.374400</td>\n",
       "      <td>1.390631</td>\n",
       "      <td>0.520000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.142700</td>\n",
       "      <td>1.181914</td>\n",
       "      <td>0.608750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.985500</td>\n",
       "      <td>1.155346</td>\n",
       "      <td>0.640625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.861500</td>\n",
       "      <td>0.984804</td>\n",
       "      <td>0.697500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.800200</td>\n",
       "      <td>1.228351</td>\n",
       "      <td>0.591250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.739400</td>\n",
       "      <td>0.806559</td>\n",
       "      <td>0.756875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.645000</td>\n",
       "      <td>0.895200</td>\n",
       "      <td>0.729375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.603500</td>\n",
       "      <td>0.933118</td>\n",
       "      <td>0.725000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.552600</td>\n",
       "      <td>0.886798</td>\n",
       "      <td>0.741875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.487700</td>\n",
       "      <td>0.798390</td>\n",
       "      <td>0.781875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.453600</td>\n",
       "      <td>0.817954</td>\n",
       "      <td>0.777500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.418500</td>\n",
       "      <td>0.817197</td>\n",
       "      <td>0.775000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.398000</td>\n",
       "      <td>0.750839</td>\n",
       "      <td>0.814375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>0.363100</td>\n",
       "      <td>0.851517</td>\n",
       "      <td>0.782500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>0.346800</td>\n",
       "      <td>0.795103</td>\n",
       "      <td>0.811250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>0.345100</td>\n",
       "      <td>0.839611</td>\n",
       "      <td>0.790625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>0.321100</td>\n",
       "      <td>0.800156</td>\n",
       "      <td>0.820625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.305500</td>\n",
       "      <td>0.820769</td>\n",
       "      <td>0.819375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>0.305800</td>\n",
       "      <td>0.838770</td>\n",
       "      <td>0.818125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>0.286800</td>\n",
       "      <td>0.820701</td>\n",
       "      <td>0.833125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>0.269100</td>\n",
       "      <td>0.806103</td>\n",
       "      <td>0.840625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>0.262700</td>\n",
       "      <td>0.779714</td>\n",
       "      <td>0.845625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>0.254500</td>\n",
       "      <td>0.812691</td>\n",
       "      <td>0.853750</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2299cb349e654ad6b87e1e4f6116ae5f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading builder script:   0%|          | 0.00/1.65k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=20000, training_loss=0.6637950981140137, metrics={'train_runtime': 2040.4088, 'train_samples_per_second': 94.099, 'train_steps_per_second': 11.762, 'total_flos': 1.052519817216e+16, 'train_loss': 0.6637950981140137, 'epoch': 25.0})"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train model ... lr = 1e-5 (resampling)\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.7508392930030823,\n",
       " 'eval_accuracy': 0.814375,\n",
       " 'eval_runtime': 5.2914,\n",
       " 'eval_samples_per_second': 302.377,\n",
       " 'eval_steps_per_second': 37.797,\n",
       " 'epoch': 25.0}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluation\n",
    "trainer.evaluate(dataset_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Save completed...\n"
     ]
    }
   ],
   "source": [
    "# Save model\n",
    "tokenizer.save_pretrained('./model')\n",
    "trainer.save_model('./model')\n",
    "print(\"Save completed...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Load model\n",
    "# # tokenizer = AutoTokenizer.from_pretrained('pretrained_WangchanBERTa/model')\n",
    "# # loaded_model = AutoModelForSequenceClassification.from_pretrained('pretrained_WangchanBERTa/model')\n",
    "# pipe = pipeline(\"text-classification\", model=\"pretrained_WangchanBERTa/model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_predict = trainer.predict(dataset_test)\n",
    "y_test_logits = y_test_predict.predictions\n",
    "y_test_prob = torch.softmax(torch.tensor(y_test_logits), dim=1) # tf.nn.softmax(y_test_logits)\n",
    "y_test_pred_labels = np.argmax(y_test_prob, axis=1)\n",
    "y_test_actual_labels = y_test_predict.label_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b0c7da0cb624928a55a5ecfcb723958",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading builder script:   0%|          | 0.00/6.77k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'f1': 0.8130519868315471}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compute f1 metric\n",
    "metric_f1 = evaluate.load(\"f1\")\n",
    "metric_f1.compute(predictions=y_test_pred_labels, references=y_test_actual_labels, average=\"weighted\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy : 0.8144\n"
     ]
    }
   ],
   "source": [
    "acc = accuracy_score(y_test_actual_labels, y_test_pred_labels)\n",
    "print(f\"Accuracy : {acc:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_prediction(prep_text):\n",
    "    inputs = tokenizer(prep_text, padding=True, truncation=True, return_tensors=\"pt\").to(device)\n",
    "    ## Perform inference\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    ## Move outputs to CPU if necessary and calculate softmax probabilities\n",
    "    softmax_probs = torch.softmax(outputs.logits, dim=1).cpu().tolist()\n",
    "    ## Extract predicted labels\n",
    "    predicted_labels = torch.argmax(outputs.logits, dim=1).tolist()\n",
    "    # predicted_labels = outputs.logits.argmax(dim=1).cpu().tolist()\n",
    "    results = [(idx2label[label], probs[label]) for label, probs in zip(predicted_labels, softmax_probs)]\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
